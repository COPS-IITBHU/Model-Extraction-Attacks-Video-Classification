import torch.nn.functional as F
import torch
import numpy as np
import torchvision
import os

# os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# from cifar10_models import *


def estimate_gradient_objective(
        args, victim_model, clone_model, x, epsilon=1e-7,
        m=5, num_classes=10, device="cpu", pre_x=False):
    # Sampling from unit sphere is the method 3 from this website:
    #  http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/
    #x = torch.Tensor(np.arange(2*1*7*7).reshape(-1, 1, 7, 7))

    # x is the fake image generated by the query generator; shape :

    # m = 'Number of steps to approximate the gradients'
    if pre_x and args.G_activation is None:
        raise ValueError(args.G_activation)

    clone_model.eval()
    clone_model.cuda()
    
    victim_model.eval()
    victim_model.cuda()
    
    with torch.no_grad():
        # Sample unit noise vector
        N = x.size(0)  # batches (B, C, T, H, W)
        C = x.size(1)  # channels
        Fr = x.size(2)  # frames in video
        S = x.size(3)  # width, height
        dim = S**2 * C  # Fr
        u = np.random.randn(N * m * dim * Fr).reshape(-1, m,Fr, dim)
        d = np.sqrt(np.sum(u ** 2, axis=-1)).reshape(-1, m,Fr, 1)
        u = torch.Tensor(u / d).view(-1, m, C,Fr, S, S)
        # To remove the randomness in the frames of the same video thus the Fr we removed.
        u = torch.cat((u, torch.zeros(N, 1, C,Fr, S, S)),
                      dim=1)
        # (B, C, T, H, W)
        evaluation_points = (x.view(-1, 1, C, Fr, S, S).cpu() +
                             epsilon * u).view(-1, C, Fr, S, S)  # N * (m + 1)
        if pre_x:
            evaluation_points = args.G_activation(
                evaluation_points)  # Apply args.G_activation function

        # Compute the approximation sequentially to allow large values of m
        pred_victim = []
        pred_clone = []
        # Hardcoded value to split the large evaluation_points tensor to fit in GPU
        max_number_points = 64 * 156
        for i in (range(N * m // max_number_points + 1)):
            pts = evaluation_points[i *
                                    max_number_points: (i+1) * max_number_points]
            pts = pts.to(device)
            pred_victim_pts = victim_model(pts).detach()
            pred_clone_pts = clone_model(pts.permute(0, 2, 1, 3, 4))
            pred_victim.append(pred_victim_pts)
            pred_clone.append(pred_clone_pts)

        pred_victim = torch.cat(pred_victim, dim=0).to(device)
        pred_clone = torch.cat(pred_clone, dim=0).to(device)

        u = u.to(device)

        if args.loss == "l1":
            loss_fn = F.l1_loss
            if args.no_logits:
                pred_victim = F.log_softmax(pred_victim, dim=1).detach()
                if args.logit_correction == 'min':
                    pred_victim -= pred_victim.min(
                        dim=1).values.view(-1, 1).detach()
                elif args.logit_correction == 'mean':
                    pred_victim -= pred_victim.mean(dim=1).view(-1, 1).detach()

        elif args.loss == "kl":
            loss_fn = F.kl_div
            pred_clone = F.log_softmax(pred_clone, dim=1)
            pred_victim = F.softmax(pred_victim.detach(), dim=1)

        else:
            raise ValueError(args.loss)

        # Compute loss
        if args.loss == "kl":
            loss_values = - loss_fn(pred_clone, pred_victim,
                                    reduction='none'
                                    ).sum(dim=1).view(-1, m + 1)
        else:
            loss_values = - loss_fn(pred_clone, pred_victim,
                                    reduction='none'
                                    ).mean(dim=1).view(-1, m + 1)

        # Compute difference following each direction
        differences = loss_values[:, :-1] - loss_values[:, -1].view(-1, 1)
        differences = differences.view(-1, m, 1, 1, 1)

        # Formula for Forward Finite Differences
        gradient_estimates = 1 / epsilon * differences * u[:, :-1]
        if args.forward_differences:
            gradient_estimates *= dim

        if args.loss == "kl":
            gradient_estimates = gradient_estimates.mean(
                dim=1).view(-1, C, S, S)
        else:
            gradient_estimates = gradient_estimates.mean(
                dim=1).view(-1, C, Fr, S, S) / (num_classes * N)

        clone_model.train()
        loss_G = loss_values[:, -1].mean()
        return gradient_estimates.detach(), loss_G


def compute_gradient(args, victim_model, clone_model, x, pre_x=False, device="cpu"):
    if pre_x and args.G_activation is None:
        raise ValueError(args.G_activation)

    clone_model.eval()
    N = x.size(0)
    x_copy = x.clone().detach().requires_grad_(True)
    x_ = x_copy.to(device)

    if pre_x:
        x_ = args.G_activation(x_)

    pred_victim = torch.tensor(victim_model(x_))
    pred_clone = clone_model(x_.permute(0, 2, 1, 3, 4))

    if args.loss == "l1":
        loss_fn = F.l1_loss
        if args.no_logits:
            pred_victim_no_logits = F.log_softmax(pred_victim, dim=1)
            if args.logit_correction == 'min':
                pred_victim = pred_victim_no_logits - \
                    pred_victim_no_logits.min(dim=1).values.view(-1, 1)
            elif args.logit_correction == 'mean':
                pred_victim = pred_victim_no_logits - \
                    pred_victim_no_logits.mean(dim=1).view(-1, 1)
            else:
                pred_victim = pred_victim_no_logits

    elif args.loss == "kl":
        loss_fn = F.kl_div
        pred_clone = F.log_softmax(pred_clone, dim=1)
        pred_victim = F.softmax(pred_victim, dim=1)

    else:
        raise ValueError(args.loss)

    loss_values = -loss_fn(pred_clone, pred_victim, reduction='mean')
    loss_values.backward()
    clone_model.train()
    return x_copy.grad, loss_values


class Args(dict):
    def __init__(self, **args):
        for k, v in args.items():
            self[k] = v